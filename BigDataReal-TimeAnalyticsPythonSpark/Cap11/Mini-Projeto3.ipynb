{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini projeto 3\n",
    "\n",
    "Prevendo a cotação de criptomoedas em tempo real com PySpark e Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão Python: 3.11.1 \n",
      "\n",
      "Author: gustavogzr\n",
      "\n",
      "seaborn   : 0.12.2\n",
      "pandas    : 2.0.3\n",
      "numpy     : 1.25.2\n",
      "matplotlib: 3.7.2\n",
      "decimal   : 1.70\n",
      "pyspark   : 3.5.2\n",
      "findspark : 2.0.1\n",
      "sys       : 3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importando bibliotecas:\n",
    "from platform import python_version\n",
    "print('Versão Python:', python_version(), '\\n')\n",
    "\n",
    "import findspark\n",
    "findspark.init() # Inicializando o findspark\n",
    "\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from pyspark import SparkConf, SparkContext # SparkConf: Configuração do Spark; SparkContext: Contexto do Spark\n",
    "from pyspark.sql import SparkSession, SQLContext # SparkSession: Sessão do Spark; SQLContext: Contexto SQL\n",
    "from pyspark.sql.types import * # Importando todos os tipos de dados do Spark\n",
    "from pyspark.sql.functions import * # Importando todas as funções do Spark\n",
    "from pyspark.ml.linalg import Vectors # Importando o tipo de dado vetor do Spark\n",
    "from pyspark.ml.feature import StringIndexer # Importando o indexador de string do Spark\n",
    "from pyspark.ml.regression import LinearRegression # Importando a regressão linear do Spark\n",
    "from pyspark.mllib.evaluation import RegressionMetrics # Importando as métricas de avaliação do Spark\n",
    "from pyspark.ml.linalg import Vectors # Importando o tipo de dado vetor do Spark\n",
    "from pyspark.ml.feature import StringIndexer # Importando o indexador de string do Spark\n",
    "from pyspark.ml.stat import Correlation # Importando a correlação do Spark\n",
    "from pyspark.ml.feature import MinMaxScaler # Importando o escalonador do Spark\n",
    "from pyspark.ml.feature import VectorAssembler # Importando o montador de vetores do Spark\n",
    "from pyspark.ml import Pipeline # Importando o pipeline do Spark\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel # Importando o otimizador de hiperparâmetros do Spark\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler # Importando o montador de vetores e o escalonador do Spark\n",
    "from pyspark.ml.evaluation import RegressionEvaluator # Importando o avaliador de regressão do Spark\n",
    "\n",
    "%reload_ext watermark\n",
    "%watermark -a \"gustavogzr\" --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatação das saídas\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_colwidth', 400)\n",
    "from matplotlib.axes._axes import _log as matplotlib_axes_logger # Removendo mensagens de aviso\n",
    "matplotlib_axes_logger.setLevel('ERROR') # Removendo mensagens de aviso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo semente aleatória (seed) para reprodutabilidade dos resultados\n",
    "rnd_seed = 23\n",
    "np.random.seed = rnd_seed\n",
    "np.random.set_state = rnd_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um Spark Context:\n",
    "sc = SparkContext(appName='Mini-Projeto-3') # Criando um SparkContext. O parâmetro appName é um nome para a aplicação Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um Spark Session: \n",
    "spark_session = SparkSession.Builder().getOrCreate() # Criando uma sessão Spark\n",
    "# a diferença entre contexto e sessão é que a sessão engloba o contexto e adiciona informações sobre a aplicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://NO00445529:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Mini-Projeto-3</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1e91743a490>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando a sessão criada:\n",
    "spark_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados a partir da sessão Spark:\n",
    "df_spark = spark_session.read.csv('.arquivos_DSA/dados/dataset.csv', header=True, inferSchema=True) # inferSchema: Infere o tipo de dado de cada coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tipo de objeto:\n",
    "type(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+----+-----+------------+-----------------+--------------+\n",
      "| Timestamp|Open|High| Low|Close|Volume_(BTC)|Volume_(Currency)|Weighted_Price|\n",
      "+----------+----+----+----+-----+------------+-----------------+--------------+\n",
      "|1325317920|4.39|4.39|4.39| 4.39|  0.45558087|     2.0000000193|          4.39|\n",
      "|1325319300| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325319360| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325319420| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325319480| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325319540| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325319600| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325319660| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345040| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345100| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345160| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345220| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345280| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345340| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345400| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345460| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345520| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345580| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345640| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345700| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "+----------+----+----+----+-----+------------+-----------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualizando os dados:\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Timestamp: integer (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume_(BTC): double (nullable = true)\n",
      " |-- Volume_(Currency): double (nullable = true)\n",
      " |-- Weighted_Price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualizar metadados:\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4856600"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar o número de linhas:\n",
    "df_spark.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling com SparkSQL (Manipulação de Dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar tabela temporária a partir do dataframe:\n",
    "df_spark.createOrReplaceTempView('dados_bitcoin')\n",
    "# A tabela temporária é uma visão temporária que pode ser utilizada para executar consultas SQL\n",
    "# Evita-se utilizar o dataframe diretamente para consultas SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+----+-----+------------+-----------------+--------------+-------------------+\n",
      "| Timestamp|Open|High| Low|Close|Volume_(BTC)|Volume_(Currency)|Weighted_Price|           dateTime|\n",
      "+----------+----+----+----+-----+------------+-----------------+--------------+-------------------+\n",
      "|1325317920|4.39|4.39|4.39| 4.39|  0.45558087|     2.0000000193|          4.39|2011-12-30 23:52:00|\n",
      "|1325319300| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|2011-12-31 00:15:00|\n",
      "|1325319360| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|2011-12-31 00:16:00|\n",
      "|1325319420| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|2011-12-31 00:17:00|\n",
      "|1325319480| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|2011-12-31 00:18:00|\n",
      "+----------+----+----+----+-----+------------+-----------------+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Executar consulta SQL:\n",
    "df_bitcoin = spark_session.sql('SELECT *, from_unixtime(timestamp) as `dateTime` FROM dados_bitcoin')\n",
    "df_bitcoin = df_bitcoin.withColumn(\"dateTime\", from_utc_timestamp('dateTime', \"UTC-6\")) # Ajustando o fuso horário\n",
    "df_bitcoin.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_bitcoin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+----+-----+------------+-----------------+--------------+-------------------+\n",
      "| Timestamp|Open|High| Low|Close|Volume_(BTC)|Volume_(Currency)|Weighted_Price|           dateTime|\n",
      "+----------+----+----+----+-----+------------+-----------------+--------------+-------------------+\n",
      "|1325317920|4.39|4.39|4.39| 4.39|  0.45558087|     2.0000000193|          4.39|2011-12-30 23:52:00|\n",
      "|1325346600|4.39|4.39|4.39| 4.39|        48.0|           210.72|          4.39|2011-12-31 07:50:00|\n",
      "|1325350740| 4.5|4.57| 4.5| 4.57| 37.86229723|     171.38033753|  4.5264114983|2011-12-31 08:59:00|\n",
      "|1325350800|4.58|4.58|4.58| 4.58|         9.0|            41.22|          4.58|2011-12-31 09:00:00|\n",
      "|1325391360|4.58|4.58|4.58| 4.58|       1.502|          6.87916|          4.58|2011-12-31 20:16:00|\n",
      "+----------+----+----+----+-----+------------+-----------------+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remoção de valores NaN (missing values):\n",
    "df_bitcoin = df_bitcoin.dropna('any')\n",
    "df_bitcoin.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3613769"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar o número de linhas:\n",
    "df_bitcoin.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Timestamp',\n",
       " 'Open',\n",
       " 'High',\n",
       " 'Low',\n",
       " 'Close',\n",
       " 'Volume_(BTC)',\n",
       " 'Volume_(Currency)',\n",
       " 'Weighted_Price',\n",
       " 'dateTime']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Colunas do dataframe:\n",
    "df_bitcoin.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+----+-----+-----------+------------+--------------+-------------------+\n",
      "| Timestamp|Open|High| Low|Close|    Vol_BTC|Vol_Currency|Weighted_Price|           dateTime|\n",
      "+----------+----+----+----+-----+-----------+------------+--------------+-------------------+\n",
      "|1325317920|4.39|4.39|4.39| 4.39| 0.45558087|2.0000000193|          4.39|2011-12-30 23:52:00|\n",
      "|1325346600|4.39|4.39|4.39| 4.39|       48.0|      210.72|          4.39|2011-12-31 07:50:00|\n",
      "|1325350740| 4.5|4.57| 4.5| 4.57|37.86229723|171.38033753|  4.5264114983|2011-12-31 08:59:00|\n",
      "|1325350800|4.58|4.58|4.58| 4.58|        9.0|       41.22|          4.58|2011-12-31 09:00:00|\n",
      "|1325391360|4.58|4.58|4.58| 4.58|      1.502|     6.87916|          4.58|2011-12-31 20:16:00|\n",
      "+----------+----+----+----+-----+-----------+------------+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renomear colunas para facilitar a manipulação de dados:\n",
    "df_bitcoin = df_bitcoin.withColumnRenamed(\n",
    "    'Volume_(BTC)', 'Vol_BTC').withColumnRenamed(\n",
    "    'Volume_(Currency)', 'Vol_Currency')\n",
    "df_bitcoin.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+----+-----+-----------+------------+--------------+-------------------+----------+--------+\n",
      "| Timestamp|Open|High| Low|Close|    Vol_BTC|Vol_Currency|Weighted_Price|           dateTime|      date|    time|\n",
      "+----------+----+----+----+-----+-----------+------------+--------------+-------------------+----------+--------+\n",
      "|1325317920|4.39|4.39|4.39| 4.39| 0.45558087|2.0000000193|          4.39|2011-12-30 23:52:00|2011-12-30|23:52:00|\n",
      "|1325346600|4.39|4.39|4.39| 4.39|       48.0|      210.72|          4.39|2011-12-31 07:50:00|2011-12-31|07:50:00|\n",
      "|1325350740| 4.5|4.57| 4.5| 4.57|37.86229723|171.38033753|  4.5264114983|2011-12-31 08:59:00|2011-12-31|08:59:00|\n",
      "|1325350800|4.58|4.58|4.58| 4.58|        9.0|       41.22|          4.58|2011-12-31 09:00:00|2011-12-31|09:00:00|\n",
      "|1325391360|4.58|4.58|4.58| 4.58|      1.502|     6.87916|          4.58|2011-12-31 20:16:00|2011-12-31|20:16:00|\n",
      "+----------+----+----+----+-----+-----------+------------+--------------+-------------------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vamos dividir o dataframe extraindo a data e hora:\n",
    "df_data = df_bitcoin.withColumn('date', split(col('dateTime'), ' ').getItem(0))\n",
    "df_data = df_data.withColumn('time', split(col('dateTime'), ' ').getItem(1))\n",
    "df_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Timestamp: integer (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Vol_BTC: double (nullable = true)\n",
      " |-- Vol_Currency: double (nullable = true)\n",
      " |-- Weighted_Price: double (nullable = true)\n",
      " |-- dateTime: timestamp (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+----+-----+-----------+------------+--------------+-------------------+----------+--------+----+\n",
      "| Timestamp|Open|High| Low|Close|    Vol_BTC|Vol_Currency|Weighted_Price|           dateTime|      date|    time|hour|\n",
      "+----------+----+----+----+-----+-----------+------------+--------------+-------------------+----------+--------+----+\n",
      "|1325317920|4.39|4.39|4.39| 4.39| 0.45558087|2.0000000193|          4.39|2011-12-30 23:52:00|2011-12-30|23:52:00|  23|\n",
      "|1325346600|4.39|4.39|4.39| 4.39|       48.0|      210.72|          4.39|2011-12-31 07:50:00|2011-12-31|07:50:00|  07|\n",
      "|1325350740| 4.5|4.57| 4.5| 4.57|37.86229723|171.38033753|  4.5264114983|2011-12-31 08:59:00|2011-12-31|08:59:00|  08|\n",
      "|1325350800|4.58|4.58|4.58| 4.58|        9.0|       41.22|          4.58|2011-12-31 09:00:00|2011-12-31|09:00:00|  09|\n",
      "|1325391360|4.58|4.58|4.58| 4.58|      1.502|     6.87916|          4.58|2011-12-31 20:16:00|2011-12-31|20:16:00|  20|\n",
      "+----------+----+----+----+-----+-----------+------------+--------------+-------------------+----------+--------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extrair a hora:\n",
    "df_data_hora = df_data.withColumn('hour', split(col('time'), ':').getItem(0))\n",
    "df_data_hora.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Timestamp: integer (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Vol_BTC: double (nullable = true)\n",
      " |-- Vol_Currency: double (nullable = true)\n",
      " |-- Weighted_Price: double (nullable = true)\n",
      " |-- dateTime: timestamp (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- hour: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data_hora.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encerrar a sessão Spark:\n",
    "spark_session.stop()\n",
    "# Encerrar o Spark Context:\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
